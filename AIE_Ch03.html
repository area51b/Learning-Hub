<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Engineering: Chapter 2 Interactive Summary</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Visualization & Content Choices:
        - Navigation: Sidebar with 7 links (JS content switching). Goal: Easy access.
        - Training Data (Slide 2): Styled HTML cards with Unicode icons for 'Multilingual' & 'Domain-Specific'. Goal: Visually differentiate.
        - Modeling & Architecture (Slide 3): HTML/CSS blocks for 'Transformer' components & 'Model Size' factors. Goal: Simple visual organization.
        - Post-Training Alignment (Slide 4): Clickable HTML/CSS flow diagram for SFT/RLHF/DPO. Goal: Interactive process explanation.
        - Sampling Strategies (Slide 5): Clickable HTML/CSS cards for Top-k/Top-p/Beam Search, expanding to show details. Goal: Focused information delivery.
        - Challenges (Slide 6): Accordion fo<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Engineering: Chapter 3 Interactive Summary - Evaluation Methodology</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Visualization & Content Choices:
        - Navigation: Sidebar with 7 links (JS content switching). Goal: Easy access.
        - Challenges (Slide 2): Accordion for detailed explanations. Chart.js bar chart for 'Investment Gap' (Model Dev vs. Eval Investment). Goal: Digestible list & visual concept.
        - LM Metrics (Slide 3): Styled cards for each metric (Entropy, Cross-Entropy, Perplexity) with HTML/CSS for formula display. Goal: Clear presentation.
        - Exact Evaluation (Slide 4): Cards for 'Functional Correctness' & 'Similarity Measurements', with sub-details for N-gram/Embedding. Goal: Structured information.
        - AI as a Judge (Slide 5): HTML/CSS diagram for concept. Accordion for 'Limitations'. Goal: Visual explanation & detailed breakdown.
        - Comparative Evaluation (Slide 6): HTML/CSS diagram for A/B comparison. List for 'Challenges'. Goal: Visual process & clear points.
        - All textual content from source.
        - CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        .content-section {
            display: none;
        }
        .content-section.active {
            display: block;
        }
        .nav-link {
            display: block;
            padding: 0.75rem 1rem;
            border-radius: 0.375rem;
            transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out;
            cursor: pointer;
        }
        .nav-link:hover {
            background-color: #f0f9ff; /* sky-50 */
            color: #0369a1; /* sky-700 */
        }
        .nav-link.active {
            background-color: #0ea5e9; /* sky-500 */
            color: white;
            font-weight: 600;
        }
        .accordion-header {
            cursor: pointer;
        }
        .accordion-content {
            display: none;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }
        .accordion-content.open {
            display: block;
            max-height: 500px; /* Adjust as needed */
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px; 
            margin-left: auto;
            margin-right: auto;
            height: 300px; 
            max-height: 350px; /* Slightly reduced for bar chart */
        }
        @media (min-width: 768px) { /* md breakpoint */
            .chart-container {
                height: 320px; /* Slightly reduced for bar chart */
            }
        }
        .metric-card, .eval-card {
            transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
        }
        .metric-card:hover, .eval-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
        }
        .formula {
            font-family: 'Courier New', Courier, monospace;
            background-color: #f8fafc; /* slate-50 */
            padding: 0.25rem 0.5rem;
            border-radius: 0.25rem;
            color: #334155; /* slate-700 */
            font-size: 0.9em;
        }
        .comparison-box {
            border: 2px dashed #cbd5e1; /* slate-300 */
            padding: 1rem;
            border-radius: 0.5rem;
            text-align: center;
        }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">

    <div class="flex flex-col md:flex-row min-h-screen">
        <nav class="w-full md:w-72 bg-white p-6 shadow-lg flex-shrink-0">
            <h1 class="text-2xl font-bold text-sky-700 mb-6 border-b pb-3">AI Engineering Ch.3</h1>
            <ul class="space-y-2">
                <li><a class="nav-link active" data-target="slide1-ch3">1. Criticality of Evaluation</a></li>
                <li><a class="nav-link" data-target="slide2-ch3">2. Challenges in Evaluating FMs</a></li>
                <li><a class="nav-link" data-target="slide3-ch3">3. Language Modeling Metrics</a></li>
                <li><a class="nav-link" data-target="slide4-ch3">4. Exact Evaluation Approaches</a></li>
                <li><a class="nav-link" data-target="slide5-ch3">5. AI as a Judge</a></li>
                <li><a class="nav-link" data-target="slide6-ch3">6. Comparative Evaluation</a></li>
                <li><a class="nav-link" data-target="slide7-ch3">7. Conclusion</a></li>
            </ul>
        </nav>

        <main class="flex-1 p-6 md:p-10 overflow-y-auto">
            
            <section id="slide1-ch3" class="content-section active">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">The Criticality of Evaluation</h2>
                    <p class="mb-6 text-slate-600">This section introduces the central theme of Chapter 3: the indispensable role of evaluation in AI engineering. It highlights the growing risks associated with powerful AI models and positions evaluation as a key, albeit challenging, component in developing responsible and reliable AI applications.</p>
                    <ul class="space-y-4 text-slate-700">
                        <li><strong class="text-sky-600">Introduction:</strong> As AI models become more powerful and widely adopted, the potential for catastrophic failures increases significantly. We've seen examples like chatbots giving harmful advice or AI generating false evidence.</li>
                        <li><strong class="text-sky-600">Core Problem:</strong> Without robust evaluation, the risks associated with AI applications (e.g., misinformation, bias, safety issues) can outweigh their potential benefits for many use cases.</li>
                        <li><strong class="text-sky-600">Key Hurdle:</strong> Evaluation is often the biggest challenge in bringing AI applications to reality, sometimes consuming the majority of development effort due to the complexity of open-ended outputs.</li>
                        <li><strong class="text-sky-600">Purpose of Chapter:</strong> This chapter covers various evaluation methods for open-ended models, their underlying mechanisms, and their inherent limitations, aiming to equip engineers with the knowledge to build better evaluation strategies.</li>
                    </ul>
                </div>
            </section>

            <section id="slide2-ch3" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Challenges of Evaluating Foundation Models</h2>
                    <p class="mb-6 text-slate-600">Evaluating Foundation Models (FMs) presents unique and significant difficulties compared to traditional Machine Learning systems. This section outlines these core challenges, emphasizing why robust evaluation strategies are both critical and complex to implement.</p>
                    
                    <div class="flex flex-col lg:flex-row gap-8">
                        <div class="lg:w-1/2">
                            <h3 class="text-xl font-semibold text-sky-600 mb-4">Key Challenges (Click to Expand):</h3>
                            <div id="challengesAccordionCh3" class="space-y-2">
                                </div>
                        </div>
                        <div class="lg:w-1/2">
                            <h3 class="text-xl font-semibold text-sky-600 mb-4 text-center">Conceptual: The Investment Gap</h3>
                            <div class="chart-container bg-slate-50 p-4 rounded-lg border border-slate-200">
                                <canvas id="investmentGapChart"></canvas>
                            </div>
                            <p class="text-sm text-slate-500 mt-2 text-center">Illustrative representation of typical investment focus.</p>
                        </div>
                    </div>
                </div>
            </section>

            <section id="slide3-ch3" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Language Modeling Metrics</h2>
                    <p class="mb-6 text-slate-600">Since many Foundation Models have a core language modeling component, understanding specific metrics for language tasks is crucial. This section details key metrics like entropy, cross-entropy, and perplexity, explaining what they measure and how they help assess a model's language understanding and generation capabilities.</p>
                    <p class="mb-4"><strong class="text-sky-600">Relevance:</strong> Crucial for assessing models with language components.</p>
                    <div class="grid md:grid-cols-2 gap-6">
                        <div class="metric-card bg-sky-50 p-4 rounded-lg border border-sky-200">
                            <h4 class="font-semibold text-sky-700 mb-1">Entropy</h4>
                            <p class="text-sm text-slate-600">Measures uncertainty or randomness in a model's predictions. Quantifies the unpredictability of the next token.</p>
                        </div>
                        <div class="metric-card bg-sky-50 p-4 rounded-lg border border-sky-200">
                            <h4 class="font-semibold text-sky-700 mb-1">Cross-Entropy</h4>
                            <p class="text-sm text-slate-600">Measures how well a model's predicted probability distribution for tokens matches the actual distribution in a target text. Lower is better.</p>
                        </div>
                        <div class="metric-card bg-sky-50 p-4 rounded-lg border border-sky-200">
                            <h4 class="font-semibold text-sky-700 mb-1">Bits-per-Character/Byte (BPC/BPB)</h4>
                            <p class="text-sm text-slate-600">Related to entropy; average bits needed to encode each character/byte given model predictions. Lower is better.</p>
                        </div>
                        <div class="metric-card bg-sky-50 p-4 rounded-lg border border-sky-200">
                            <h4 class="font-semibold text-sky-700 mb-1">Perplexity</h4>
                            <p class="text-sm text-slate-600 mb-2">Derived from cross-entropy; geometric mean of the inverse probability of each word. Lower perplexity indicates a better (less "perplexed") model.</p>
                            <p class="text-xs text-slate-500">Interpretation: A perplexity of <span class="formula">P</span> means the model is as confused as if choosing uniformly among <span class="formula">P</span> words at each step.</p>
                        </div>
                    </div>
                </div>
            </section>

            <section id="slide4-ch3" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Exact Evaluation Approaches</h2>
                    <p class="mb-6 text-slate-600">Exact evaluation methods provide objective, quantifiable assessments by comparing model outputs against predefined criteria or reference data. This section explores two main categories: functional correctness and similarity measurements, outlining their goals and common techniques.</p>
                    <p class="mb-4"><strong class="text-sky-600">Definition:</strong> Aim for objective, quantifiable assessments against a reference or criteria.</p>
                    <div class="space-y-6">
                        <div class="eval-card bg-teal-50 p-6 rounded-lg border border-teal-200">
                            <h3 class="text-xl font-semibold text-teal-700 mb-2">Functional Correctness</h3>
                            <p class="text-sm text-slate-600 mb-2"><strong class="text-teal-600">Goal:</strong> Verify if the model's output fulfills a specific, predefined function or task correctly.</p>
                            <p class="text-sm text-slate-600"><strong class="text-teal-600">Examples:</strong>
                                <ul class="list-disc list-inside ml-4 text-xs text-slate-500">
                                    <li>Code generation: Does the code compile and pass unit tests?</li>
                                    <li>Summarization: Does the summary include all key predefined facts?</li>
                                    <li>Question Answering: Is the answer factually correct based on a knowledge base?</li>
                                </ul>
                            </p>
                        </div>
                        <div class="eval-card bg-teal-50 p-6 rounded-lg border border-teal-200">
                            <h3 class="text-xl font-semibold text-teal-700 mb-2">Similarity Measurements Against Reference Data</h3>
                            <p class="text-sm text-slate-600 mb-2"><strong class="text-teal-600">Goal:</strong> Quantify how similar a model's output is to a human-written or "gold standard" reference.</p>
                            <p class="text-sm text-slate-600 mb-3"><strong class="text-teal-600">Techniques:</strong></p>
                            <div class="space-y-3">
                                <div class="p-3 bg-white rounded border border-teal-100">
                                    <h4 class="font-medium text-teal-600 text-sm">N-gram Overlap (e.g., BLEU, ROUGE)</h4>
                                    <p class="text-xs text-slate-500">Measures the overlap of sequences of words (n-grams) between generated and reference text. Useful for tasks like machine translation and summarization.</p>
                                </div>
                                <div class="p-3 bg-white rounded border border-teal-100">
                                    <h4 class="font-medium text-teal-600 text-sm">Embedding-based Similarity</h4>
                                    <p class="text-xs text-slate-500 mb-1">Uses vector embeddings (dense representations capturing semantic meaning) to calculate similarity (e.g., cosine similarity) between generated and reference texts. Can capture semantic similarity better than pure n-gram overlap.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="slide5-ch3" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">AI as a Judge</h2>
                    <p class="mb-6 text-slate-600">"AI as a Judge" is an emerging evaluation paradigm where another AI model, typically a powerful LLM, assesses the quality of an AI application's output. This section explains the concept, its rationale, methodology, limitations, and the types of models suitable for this role.</p>
                    
                    <div class="text-center mb-6 p-4 bg-slate-100 rounded-lg">
                        <p class="text-lg font-medium text-slate-700">Input ‚ûî <span class="text-sky-600 font-semibold">[AI Application]</span> ‚ûî Output</p>
                        <p class="text-2xl my-2">‚Üì</p>
                        <p class="text-lg font-medium text-slate-700">(Output + Criteria) ‚ûî <span class="text-teal-600 font-semibold">[AI Judge Model]</span> ‚ûî Evaluation Score/Feedback</p>
                        <p class="text-xs text-slate-500 mt-1">Conceptual flow of AI as a Judge</p>
                    </div>

                    <div class="grid md:grid-cols-2 gap-6 mb-6">
                        <div>
                            <h3 class="text-lg font-semibold text-sky-600 mb-2">Why AI as a Judge?</h3>
                            <ul class="list-disc list-inside text-sm space-y-1 text-slate-700">
                                <li>Scalability: Evaluates large volumes quickly.</li>
                                <li>Cost-effectiveness: Cheaper than human evaluation at scale.</li>
                                <li>Consistency: Can be more consistent than multiple human evaluators (if prompted well).</li>
                            </ul>
                        </div>
                        <div>
                            <h3 class="text-lg font-semibold text-sky-600 mb-2">How to Use AI as a Judge?</h3>
                            <ul class="list-disc list-inside text-sm space-y-1 text-slate-700">
                                <li>Provide clear input, generated output, and a specific rubric/criteria.</li>
                                <li>The judge model then provides a score or qualitative assessment.</li>
                            </ul>
                        </div>
                    </div>
                    
                    <h3 class="text-lg font-semibold text-sky-600 mb-3">Limitations & Considerations:</h3>
                    <div id="aiJudgeLimitationsAccordion" class="space-y-2 mb-4">
                        </div>

                    <p class="text-sm text-slate-700"><strong class="text-sky-600">What Models Can Act as Judges?</strong> Typically, large, capable language models that have undergone extensive post-training alignment are used, as they have a better understanding of nuance and instruction following.</p>
                </div>
            </section>

            <section id="slide6-ch3" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Ranking Models with Comparative Evaluation</h2>
                    <p class="mb-6 text-slate-600">Comparative evaluation offers an alternative to scoring models in isolation. Instead, it focuses on directly comparing outputs from two or more models to determine which is better. This section explains this approach, its methodology, and associated challenges.</p>
                    
                    <div class="grid md:grid-cols-2 gap-8 items-center">
                        <div>
                            <h3 class="text-lg font-semibold text-sky-600 mb-2">Alternative Approach:</h3>
                            <p class="text-sm text-slate-700 mb-3">Instead of evaluating models independently on absolute scores, compare them directly against each other for a given input.</p>
                            <h3 class="text-lg font-semibold text-sky-600 mb-2">Methodology:</h3>
                            <p class="text-sm text-slate-700 mb-3">Present two or more model outputs for the same input to evaluators (human or AI) and ask them to choose which one is better based on specified criteria.</p>
                             <p class="text-sm text-slate-700"><strong class="text-sky-600">Common in Sports:</strong> Similar to Elo ratings in chess, where rankings are based on head-to-head match outcomes.</p>
                        </div>
                        <div class="text-center p-4 bg-slate-100 rounded-lg">
                            <p class="text-sm text-slate-500 mb-2">Input: "Summarize this article"</p>
                            <div class="flex justify-around items-start space-x-2">
                                <div class="comparison-box flex-1">Model A Output</div>
                                <div class="self-center text-xl text-slate-400">vs</div>
                                <div class="comparison-box flex-1">Model B Output</div>
                            </div>
                            <p class="text-2xl my-2 text-slate-400">‚ûî</p>
                            <div class="comparison-box bg-sky-100 border-sky-300">Evaluator (Human/AI) Chooses Better Output</div>
                             <p class="text-xs text-slate-500 mt-1">Conceptual flow of Comparative Evaluation</p>
                        </div>
                    </div>

                    <h3 class="text-lg font-semibold text-sky-600 mt-8 mb-3">Challenges:</h3>
                    <ul class="list-disc list-inside text-sm space-y-1 text-slate-700 mb-4">
                        <li>Collecting preference signals can be expensive (especially for human evaluation).</li>
                        <li>Defining "better" can be subjective and highly context-dependent.</li>
                        <li>Requires careful design of the comparison setup to avoid biases.</li>
                        <li>May not provide granular insights into specific model weaknesses.</li>
                    </ul>
                    <p class="text-sm text-slate-700"><strong class="text-sky-600">Future:</strong> This approach is gaining traction in AI evaluation, motivating the development of specialized "preference models" (AI judges designed to predict user preferences more accurately).</p>
                </div>
            </section>

            <section id="slide7-ch3" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Conclusion: The Importance of Robust Evaluation</h2>
                    <p class="mb-6 text-slate-600">Chapter 3 underscores that a comprehensive and robust evaluation strategy is not just beneficial but paramount for the successful and safe deployment of AI applications, particularly those built on open-ended foundation models. No single method is a silver bullet; a combination is often required.</p>
                    <ul class="space-y-3 list-disc list-inside text-slate-700">
                        <li>Robust evaluation is critical for mitigating risks and ensuring the quality of AI systems.</li>
                        <li>A multifaceted approach is often necessary, combining:
                            <ul class="list-circle list-inside ml-6 text-sm text-slate-600">
                                <li>Quantitative language modeling metrics (e.g., perplexity).</li>
                                <li>Exact evaluation methods (functional correctness, similarity to references).</li>
                                <li>Subjective but scalable approaches like AI-as-a-Judge.</li>
                                <li>Comparative ranking methods.</li>
                            </ul>
                        </li>
                        <li>Despite its complexity and resource intensity, investing in a reliable evaluation pipeline is essential to identify improvement opportunities, benchmark progress, and build trustworthy AI.</li>
                        <li>Evaluation must be considered holistically, integrated throughout the AI development lifecycle, not as an afterthought.</li>
                    </ul>
                </div>
            </section>

        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const navLinks = document.querySelectorAll('.nav-link');
            const contentSections = document.querySelectorAll('.content-section');
            
            function showSection(targetId) {
                contentSections.forEach(section => section.classList.remove('active'));
                const activeSection = document.getElementById(targetId);
                if (activeSection) activeSection.classList.add('active');
                
                navLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.dataset.target === targetId) link.classList.add('active');
                });
                document.querySelector('main').scrollTop = 0;
            }

            navLinks.forEach(link => {
                link.addEventListener('click', function (e) {
                    e.preventDefault();
                    showSection(this.dataset.target);
                });
            });

            // Generic Accordion Initializer
            function initializeAccordion(containerId, itemsData, itemClasses, headerClasses, contentClasses, arrowClasses) {
                const accordionContainer = document.getElementById(containerId);
                if (!accordionContainer) return;
                accordionContainer.innerHTML = ''; // Clear previous items

                itemsData.forEach(itemData => {
                    const itemDiv = document.createElement('div');
                    itemDiv.className = itemClasses || 'accordion-item border border-slate-200 rounded-lg';
                    
                    const headerDiv = document.createElement('div');
                    headerDiv.className = headerClasses || 'accordion-header bg-slate-50 p-3 flex justify-between items-center rounded-t-lg hover:bg-slate-100 transition';
                    headerDiv.innerHTML = `<span class="font-medium text-slate-700">${itemData.title}</span><span class="arrow ${arrowClasses || 'text-slate-700'} transform transition-transform duration-300">‚ñº</span>`;
                    
                    const contentDiv = document.createElement('div');
                    contentDiv.className = contentClasses || 'accordion-content p-3 bg-white rounded-b-lg';
                    contentDiv.innerHTML = `<p class="text-slate-600 text-sm">${itemData.content}</p>`;
                    
                    itemDiv.appendChild(headerDiv);
                    itemDiv.appendChild(contentDiv);
                    accordionContainer.appendChild(itemDiv);

                    headerDiv.addEventListener('click', () => {
                        const isOpen = contentDiv.classList.contains('open');
                        if (isOpen) {
                            contentDiv.classList.remove('open');
                            contentDiv.style.maxHeight = null;
                            headerDiv.querySelector('.arrow').classList.remove('rotate-180');
                        } else {
                            contentDiv.classList.add('open');
                            contentDiv.style.maxHeight = contentDiv.scrollHeight + "px";
                            headerDiv.querySelector('.arrow').classList.add('rotate-180');
                        }
                    });
                });
            }

            // Data for Challenges Accordion (Slide 2)
            const challengesDataCh3 = [
                { title: 'Complexity & Open-Ended Nature', content: 'FMs produce diverse, often unpredictable outputs, making it hard to define a single "correct" answer or pre-specify all desired behaviors.' },
                { title: 'Output Variability', content: 'Slight changes in input prompts or model parameters can lead to significantly different outputs, complicating consistent evaluation.' },
                { title: 'Lack of Guardrails', content: 'Implementing strict controls or ensuring outputs adhere to specific formats/constraints is challenging with generative models.' },
                { title: 'Human-in-the-Loop Necessity', content: 'Automated metrics often miss nuances. Human judgment is crucial for assessing quality, relevance, safety, and fairness, but it is slow and expensive.' }
            ];
            initializeAccordion('challengesAccordionCh3', challengesDataCh3, 
                'accordion-item border border-rose-200 rounded-lg', 
                'accordion-header bg-rose-50 p-3 flex justify-between items-center rounded-t-lg hover:bg-rose-100 transition',
                'accordion-content p-3 bg-white rounded-b-lg',
                'text-rose-700'
            );
            
            // Data for AI Judge Limitations Accordion (Slide 5)
            const aiJudgeLimitations = [
                { title: 'Subjectivity & Bias', content: 'The AI judge\'s evaluation is influenced by its own training data and inherent biases, which may not align with desired evaluation criteria.' },
                { title: 'Potential for Hallucinations', content: 'The AI judge itself can hallucinate, providing incorrect or nonsensical assessments of the evaluated output.' },
                { title: 'Requires Validation', content: 'AI judge outputs must be regularly validated and correlated with human judgments to ensure reliability and trustworthiness.' },
                { title: 'Prompt Sensitivity', content: 'The quality and consistency of the AI judge\'s evaluation heavily depend on the clarity, specificity, and design of the prompt given to it.' }
            ];
            initializeAccordion('aiJudgeLimitationsAccordion', aiJudgeLimitations,
                'accordion-item border border-amber-200 rounded-lg',
                'accordion-header bg-amber-50 p-3 flex justify-between items-center rounded-t-lg hover:bg-amber-100 transition',
                'accordion-content p-3 bg-white rounded-b-lg',
                'text-amber-700'
            );

            // Chart.js for Investment Gap (Slide 2)
            const investmentCtx = document.getElementById('investmentGapChart');
            if (investmentCtx) {
                new Chart(investmentCtx, {
                    type: 'bar',
                    data: {
                        labels: ['Model & App Development', 'Evaluation Investment'],
                        datasets: [{
                            label: 'Relative Focus/Investment',
                            data: [85, 15], // Conceptual values
                            backgroundColor: [
                                'rgba(59, 130, 246, 0.6)', // blue-500
                                'rgba(249, 115, 22, 0.6)'  // orange-500
                            ],
                            borderColor: [
                                'rgba(59, 130, 246, 1)',
                                'rgba(249, 115, 22, 1)'
                            ],
                            borderWidth: 1
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        indexAxis: 'y',
                        scales: {
                            x: {
                                beginAtZero: true,
                                title: { display: true, text: 'Conceptual Investment Units' }
                            }
                        },
                        plugins: {
                            legend: { display: false },
                            tooltip: {
                                callbacks: {
                                    label: function(context) {
                                        return context.dataset.label + ': ' + context.raw + ' units';
                                    }
                                }
                            }
                        }
                    }
                });
            }
            
            if (navLinks.length > 0) showSection(navLinks[0].dataset.target);
        });
    </script>
</body>
</html>
r textual details of each challenge. Chart.js Radar chart for conceptual severity visualization. Goal: Digestible list & visual summary.
        - All textual content from source.
        - CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        .content-section {
            display: none;
        }
        .content-section.active {
            display: block;
        }
        .nav-link {
            display: block;
            padding: 0.75rem 1rem;
            border-radius: 0.375rem;
            transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out;
            cursor: pointer;
        }
        .nav-link:hover {
            background-color: #f0f9ff; /* sky-50 */
            color: #0369a1; /* sky-700 */
        }
        .nav-link.active {
            background-color: #0ea5e9; /* sky-500 */
            color: white;
            font-weight: 600;
        }
        .interactive-card {
            cursor: pointer;
            transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
        }
        .interactive-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1), 0 4px 6px -2px rgba(0,0,0,0.05);
        }
        .flow-step {
            cursor: pointer;
            transition: background-color 0.2s;
        }
        .flow-step:hover {
            background-color: #e0f2fe; /* sky-100 */
        }
        .flow-description {
            display: none;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.5s ease-in-out, padding 0.5s ease-in-out;
        }
        .flow-description.open {
            display: block;
            max-height: 200px; /* Adjust as needed */
            padding-top: 0.5rem;
            padding-bottom: 0.5rem;
        }
        .accordion-header {
            cursor: pointer;
        }
        .accordion-content {
            display: none;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }
        .accordion-content.open {
            display: block;
            max-height: 500px; /* Adjust as needed */
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 500px; /* Adjusted for radar chart aesthetics */
            margin-left: auto;
            margin-right: auto;
            height: 350px; 
            max-height: 450px;
        }
        @media (min-width: 768px) { /* md breakpoint */
            .chart-container {
                height: 400px;
            }
        }
    </style>
</head>
<body class="bg-slate-50 text-slate-800">

    <div class="flex flex-col md:flex-row min-h-screen">
        <nav class="w-full md:w-72 bg-white p-6 shadow-lg flex-shrink-0">
            <h1 class="text-2xl font-bold text-sky-700 mb-6 border-b pb-3">AI Engineering Ch.2</h1>
            <ul class="space-y-2">
                <li><a class="nav-link active" data-target="slide1-ch2">1. Intro to FMs</a></li>
                <li><a class="nav-link" data-target="slide2-ch2">2. Training Data</a></li>
                <li><a class="nav-link" data-target="slide3-ch2">3. Modeling & Architecture</a></li>
                <li><a class="nav-link" data-target="slide4-ch2">4. Post-Training Alignment</a></li>
                <li><a class="nav-link" data-target="slide5-ch2">5. Sampling Strategies</a></li>
                <li><a class="nav-link" data-target="slide6-ch2">6. Challenges in FMs</a></li>
                <li><a class="nav-link" data-target="slide7-ch2">7. Conclusion</a></li>
            </ul>
        </nav>

        <main class="flex-1 p-6 md:p-10 overflow-y-auto">
            
            <section id="slide1-ch2" class="content-section active">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Introduction to Foundation Models</h2>
                    <p class="mb-6 text-slate-600">This initial section sets the stage for Chapter 2, emphasizing the importance of understanding the core components and mechanisms of Foundation Models (FMs). It highlights that FMs are central to modern AI applications and provides a roadmap of the key areas that will be explored to build this understanding.</p>
                    <ul class="space-y-3 list-disc list-inside text-slate-700">
                        <li><strong class="text-sky-600">Purpose:</strong> This chapter delves deeper into the foundational aspects of AI models, explaining their underlying mechanisms and the factors influencing their behavior.</li>
                        <li><strong class="text-sky-600">Core Idea:</strong> Foundation models are the backbone of modern AI applications, and understanding how they are built and operate is crucial for effective AI engineering.</li>
                        <li><strong class="text-sky-600">Key Areas:</strong> Training data, model architecture, post-training alignment, and output sampling strategies.</li>
                    </ul>
                </div>
            </section>

            <section id="slide2-ch2" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Training Data</h2>
                    <p class="mb-6 text-slate-600">The quality and nature of training data are paramount to the performance and capabilities of Foundation Models. This section explores the critical role of data, the challenges associated with it, and how different data strategies lead to specialized model types like multilingual or domain-specific FMs.</p>
                    <p class="mb-4 text-slate-700"><strong class="text-sky-600">Foundation of FMs:</strong> Models heavily rely on large, diverse datasets for pre-training.</p>
                    <p class="mb-4 text-slate-700"><strong class="text-sky-600">Data Quality:</strong> Effectiveness is directly tied to the quality and breadth of training data.</p>
                    <p class="mb-6 text-slate-700"><strong class="text-sky-600">Challenges:</strong> Common datasets can contain misinformation, bias, and low-quality content, necessitating effective filtering.</p>
                    
                    <h3 class="text-xl font-semibold text-sky-600 mb-4">Types of Models based on Data:</h3>
                    <div class="grid md:grid-cols-2 gap-6">
                        <div class="interactive-card bg-sky-50 p-6 rounded-lg border border-sky-200">
                            <h4 class="text-lg font-semibold text-sky-700 mb-2">üåê Multilingual Models</h4>
                            <p class="text-slate-600 text-sm">Trained on data from multiple languages for broader applicability and understanding across linguistic contexts.</p>
                        </div>
                        <div class="interactive-card bg-teal-50 p-6 rounded-lg border border-teal-200">
                            <h4 class="text-lg font-semibold text-teal-700 mb-2">üî¨ Domain-Specific Models</h4>
                            <p class="text-slate-600 text-sm">Specialized models for niche fields (e.g., genetic research, medical imaging) require curated, domain-specific datasets to achieve high performance and relevance.</p>
                        </div>
                    </div>
                </div>
            </section>

            <section id="slide3-ch2" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Modeling & Architecture</h2>
                    <p class="mb-6 text-slate-600">The architecture and scale of a Foundation Model are critical determinants of its capabilities. This section discusses the dominant Transformer architecture, its alternatives, how model size is measured, the principles of scaling laws, and the bottlenecks encountered as models grow larger.</p>
                    
                    <div class="mb-8">
                        <h3 class="text-xl font-semibold text-sky-600 mb-3">Model Architecture: The Structural Design</h3>
                        <div class="space-y-4">
                            <div class="p-4 bg-slate-100 rounded-lg">
                                <h4 class="font-medium text-sky-700">Transformer (Dominant for Language)</h4>
                                <p class="text-sm text-slate-600">Key Components: Self-Attention Mechanisms, Multi-Head Attention, Positional Encodings, Feed-Forward Networks.</p>
                                <div class="mt-2 text-xs text-slate-500">Example Flow: Input ‚ûî Multi-Head Attention ‚ûî Add & Norm ‚ûî Feed Forward ‚ûî Add & Norm ‚ûî Output</div>
                            </div>
                            <div class="p-4 bg-slate-100 rounded-lg">
                                <h4 class="font-medium text-sky-700">Alternatives Emerging</h4>
                                <p class="text-sm text-slate-600">State-Space Models (e.g., Mamba, H3) are being explored for efficiency and different inductive biases.</p>
                            </div>
                        </div>
                    </div>

                    <div class="mb-8">
                        <h3 class="text-xl font-semibold text-sky-600 mb-3">Model Size: Key Metrics</h3>
                        <div class="grid sm:grid-cols-3 gap-4">
                            <div class="p-3 bg-teal-50 rounded-lg text-center">
                                <p class="text-2xl font-bold text-teal-600">‚öôÔ∏è</p>
                                <p class="font-medium text-teal-700 text-sm">Parameters</p>
                            </div>
                            <div class="p-3 bg-teal-50 rounded-lg text-center">
                                <p class="text-2xl font-bold text-teal-600">üìÑ</p>
                                <p class="font-medium text-teal-700 text-sm">Training Tokens</p>
                            </div>
                            <div class="p-3 bg-teal-50 rounded-lg text-center">
                                <p class="text-2xl font-bold text-teal-600">üíª</p>
                                <p class="font-medium text-teal-700 text-sm">FLOPs (Compute)</p>
                            </div>
                        </div>
                    </div>
                     <div class="space-y-3">
                        <p><strong class="text-sky-600">Scaling Laws:</strong> Principles guiding the optimal balance between model size, data size, and compute budget for improved performance.</p>
                        <p><strong class="text-sky-600">Scaling Bottlenecks:</strong> Understanding limitations in data quality, compute availability, and algorithmic efficiency as models continue to scale.</p>
                    </div>
                </div>
            </section>

            <section id="slide4-ch2" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Post-Training Alignment</h2>
                    <p class="mb-6 text-slate-600">Raw pre-trained models often don't align perfectly with human expectations or values. Post-training alignment is a crucial step to refine these models, making their responses more helpful, harmless, and honest. This section outlines the necessity, goals, and key techniques for this process.</p>
                    <p class="mb-2"><strong class="text-sky-600">Necessity:</strong> Pre-trained models may produce outputs not aligned with human values or specific user intentions due to raw training data.</p>
                    <p class="mb-6"><strong class="text-sky-600">Goal:</strong> To ensure models communicate in a human-like, coherent, and aligned manner.</p>
                    
                    <h3 class="text-xl font-semibold text-sky-600 mb-4">Alignment Techniques Flow (Click steps for details):</h3>
                    <div class="flex flex-col sm:flex-row items-stretch justify-around space-y-4 sm:space-y-0 sm:space-x-2 text-center mb-6" id="alignmentFlow">
                        <div class="flow-step flex-1 p-3 border border-slate-300 rounded-lg bg-slate-100" data-step="sft">
                            <p class="font-medium">1. Supervised Finetuning (SFT)</p>
                            <div class="flow-description text-sm text-slate-600">Training on a smaller, high-quality dataset of desired input-output pairs (e.g., curated Q&A, instructions). Helps teach the model the desired style and format.</div>
                        </div>
                        <div class="sm:self-center text-2xl text-slate-400 mx-2 hidden sm:block">‚ûî</div>
                        <div class="flow-step flex-1 p-3 border border-slate-300 rounded-lg bg-slate-100" data-step="pref">
                            <p class="font-medium">2. Preference Finetuning</p>
                             <div class="flow-description text-sm text-slate-600">Optimizing models based on human preferences, typically by comparing two or more model outputs and selecting the better one.</div>
                        </div>
                    </div>
                     <div id="preferenceTechniques" class="hidden ml-0 sm:ml-8 md:ml-16 lg:ml-24 pl-4 border-l-2 border-sky-300 space-y-3 mb-6">
                        <div class="flow-step p-3 border border-sky-200 rounded-lg bg-sky-50" data-step="rlhf">
                            <p class="font-medium text-sky-700">2a. RLHF (Reinforcement Learning from Human Feedback)</p>
                            <div class="flow-description text-sm text-slate-600">Involves training a separate 'reward model' to predict human preferences, then using reinforcement learning to optimize the main FM against this reward model.</div>
                        </div>
                         <div class="flow-step p-3 border border-sky-200 rounded-lg bg-sky-50" data-step="dpo">
                            <p class="font-medium text-sky-700">2b. DPO (Direct Preference Optimization)</p>
                            <div class="flow-description text-sm text-slate-600">A simpler method that directly optimizes the language model policy based on preference data, often bypassing the need for an explicit reward model.</div>
                        </div>
                    </div>
                    <p class="text-sm text-slate-500 text-center">This flow leads to a more aligned and useful Foundation Model.</p>
                </div>
            </section>

            <section id="slide5-ch2" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Sampling Strategies for Output Generation</h2>
                    <p class="mb-6 text-slate-600">Foundation Models generate text probabilistically. Understanding sampling strategies is key to controlling the nature of their output, from deterministic and factual to creative and diverse. This section explains the fundamentals and common strategies used.</p>
                    <p class="mb-2"><strong class="text-sky-600">Probabilistic Nature:</strong> Language models generate outputs probabilistically, predicting the next token based on context.</p>
                    <p class="mb-6"><strong class="text-sky-600">Sampling Fundamentals:</strong> How models select tokens from their probability distribution.</p>

                    <div class="grid md:grid-cols-3 gap-6 mb-6" id="samplingStrategiesContainer">
                        <div class="interactive-card p-4 border border-teal-200 rounded-lg bg-teal-50 sampling-card" data-details="Selects from the 'k' most probable next tokens. A smaller 'k' makes output more focused, a larger 'k' more diverse.">
                            <h4 class="font-semibold text-teal-700 mb-2">Top-k Sampling</h4>
                            <p class="text-sm text-slate-600">Chooses from a fixed number (k) of most likely tokens.</p>
                            <div class="sampling-details hidden mt-2 p-2 bg-white rounded text-xs border border-teal-300"></div>
                        </div>
                        <div class="interactive-card p-4 border border-teal-200 rounded-lg bg-teal-50 sampling-card" data-details="Selects from the smallest set of tokens whose cumulative probability exceeds 'p'. Adapts to context, allowing for more dynamic diversity.">
                            <h4 class="font-semibold text-teal-700 mb-2">Top-p (Nucleus) Sampling</h4>
                            <p class="text-sm text-slate-600">Chooses from tokens whose cumulative probability is above a threshold (p).</p>
                            <div class="sampling-details hidden mt-2 p-2 bg-white rounded text-xs border border-teal-300"></div>
                        </div>
                        <div class="interactive-card p-4 border border-teal-200 rounded-lg bg-teal-50 sampling-card" data-details="Explores multiple potential sequences (beams) simultaneously and selects the overall most probable sequence. Often used for higher quality, more coherent outputs.">
                            <h4 class="font-semibold text-teal-700 mb-2">Beam Search</h4>
                            <p class="text-sm text-slate-600">Keeps track of multiple likely sequences (beams) to find the best one.</p>
                            <div class="sampling-details hidden mt-2 p-2 bg-white rounded text-xs border border-teal-300"></div>
                        </div>
                    </div>
                    <p class="mb-2"><strong class="text-sky-600">Parameters:</strong> Temperature (controls creativity/randomness), top-k, top-p, etc., influence output diversity and determinism.</p>
                    <p><strong class="text-sky-600">Structured Outputs:</strong> Many providers offer features to constrain model output to a predefined schema (e.g., JSON), ensuring predictability for applications.</p>
                </div>
            </section>

            <section id="slide6-ch2" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Challenges in Understanding FMs</h2>
                    <p class="mb-6 text-slate-600">Despite their power, Foundation Models present several challenges that AI engineers must navigate. These include issues with consistency, factual accuracy, bias, and the difficulty of interpreting their decisions. Effective evaluation strategies are crucial to mitigate these challenges.</p>
                    
                    <div class="flex flex-col lg:flex-row gap-6">
                        <div class="lg:w-1/2">
                            <h3 class="text-xl font-semibold text-sky-600 mb-4">Key Challenges (Click to Expand):</h3>
                            <div id="challengesAccordion" class="space-y-2">
                                </div>
                        </div>
                        <div class="lg:w-1/2">
                             <h3 class="text-xl font-semibold text-sky-600 mb-4 text-center">Conceptual Severity of Challenges</h3>
                            <div class="chart-container bg-slate-100 p-2 rounded-lg">
                                <canvas id="challengesRadarChart"></canvas>
                            </div>
                        </div>
                    </div>
                     <p class="mt-6"><strong class="text-sky-600">Evaluation:</strong> Evaluating open-ended, powerful models remains a significant challenge, requiring robust and often human-in-the-loop approaches.</p>
                </div>
            </section>

            <section id="slide7-ch2" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-lg">
                    <h2 class="text-3xl font-semibold text-sky-700 mb-6">Conclusion: Navigating Foundation Models</h2>
                    <p class="mb-6 text-slate-600">Chapter 2 provides a crucial dive into the mechanics and considerations surrounding Foundation Models. By understanding their training, architecture, alignment, and output generation, AI engineers are better equipped to build effective and responsible AI applications. While challenges persist, a solid grasp of these fundamentals is key to navigating the evolving landscape of AI.</p>
                    <ul class="space-y-3 list-disc list-inside text-slate-700">
                        <li>Chapter 2 provides a comprehensive overview of the inner workings and practical considerations of foundation models.</li>
                        <li>Understanding data influences, architectural choices, post-training alignment, and sampling is crucial for effective AI engineering.</li>
                        <li>Despite advancements, challenges like hallucinations and inconsistencies require ongoing attention and robust evaluation strategies.</li>
                        <li>The insights from this chapter are fundamental for building reliable, aligned, and high-performing AI applications.</li>
                    </ul>
                </div>
            </section>

        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const navLinks = document.querySelectorAll('.nav-link');
            const contentSections = document.querySelectorAll('.content-section');
            
            function showSection(targetId) {
                contentSections.forEach(section => section.classList.remove('active'));
                const activeSection = document.getElementById(targetId);
                if (activeSection) activeSection.classList.add('active');
                
                navLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.dataset.target === targetId) link.classList.add('active');
                });
                document.querySelector('main').scrollTop = 0;
            }

            navLinks.forEach(link => {
                link.addEventListener('click', function (e) {
                    e.preventDefault();
                    showSection(this.dataset.target);
                });
            });

            // Accordion functionality (generic)
            function initializeAccordion(containerId, items) {
                const accordionContainer = document.getElementById(containerId);
                if (!accordionContainer) return;
                accordionContainer.innerHTML = ''; // Clear previous items

                items.forEach(itemData => {
                    const itemDiv = document.createElement('div');
                    itemDiv.className = 'accordion-item border border-rose-200 rounded-lg';
                    
                    const headerDiv = document.createElement('div');
                    headerDiv.className = 'accordion-header bg-rose-50 p-3 flex justify-between items-center rounded-t-lg hover:bg-rose-100 transition';
                    headerDiv.innerHTML = `<span class="font-medium text-rose-700">${itemData.title}</span><span class="arrow text-rose-700 transform transition-transform duration-300">‚ñº</span>`;
                    
                    const contentDiv = document.createElement('div');
                    contentDiv.className = 'accordion-content p-3 bg-white rounded-b-lg';
                    contentDiv.innerHTML = `<p class="text-slate-600 text-sm">${itemData.content}</p>`;
                    
                    itemDiv.appendChild(headerDiv);
                    itemDiv.appendChild(contentDiv);
                    accordionContainer.appendChild(itemDiv);

                    headerDiv.addEventListener('click', () => {
                        const isOpen = contentDiv.classList.contains('open');
                        // Optional: Close other open accordions in this group
                        // accordionContainer.querySelectorAll('.accordion-content.open').forEach(openContent => {
                        //     if (openContent !== contentDiv) {
                        //         openContent.classList.remove('open');
                        //         openContent.style.maxHeight = null;
                        //         openContent.previousElementSibling.querySelector('.arrow').classList.remove('rotate-180');
                        //     }
                        // });
                        if (isOpen) {
                            contentDiv.classList.remove('open');
                            contentDiv.style.maxHeight = null;
                            headerDiv.querySelector('.arrow').classList.remove('rotate-180');
                        } else {
                            contentDiv.classList.add('open');
                            contentDiv.style.maxHeight = contentDiv.scrollHeight + "px";
                            headerDiv.querySelector('.arrow').classList.add('rotate-180');
                        }
                    });
                });
            }
            
            // Data for Challenges Accordion
            const challengesData = [
                { title: 'Inconsistencies', content: 'Model behavior can be unpredictable, yielding different outputs for similar inputs or failing to maintain coherence over long interactions.' },
                { title: 'Hallucinations', content: 'Models may generate text that is factually incorrect, nonsensical, or not grounded in the provided context, sometimes with high confidence.' },
                { title: 'Bias', content: 'FMs can inherit and amplify societal biases present in their vast training data, leading to unfair, discriminatory, or stereotyped outputs.' },
                { title: 'Interpretability', content: 'The "black box" nature of large models makes it difficult to understand why a specific output was generated, hindering debugging and trust.' },
                { title: 'Evaluation Complexity', content: 'Assessing the quality of open-ended generative outputs is hard. Traditional metrics often fall short, requiring complex benchmarks and human oversight.' }
            ];
            initializeAccordion('challengesAccordion', challengesData);

            // Alignment Flow Interaction
            const alignmentFlowContainer = document.getElementById('alignmentFlow');
            const preferenceTechniquesDiv = document.getElementById('preferenceTechniques');
            if (alignmentFlowContainer && preferenceTechniquesDiv) {
                alignmentFlowContainer.querySelectorAll('.flow-step').forEach(step => {
                    const description = step.querySelector('.flow-description');
                    step.addEventListener('click', () => {
                        const isOpen = description.classList.contains('open');
                        // Close all descriptions first
                        alignmentFlowContainer.querySelectorAll('.flow-description.open').forEach(d => {
                            if (d !== description) {
                                d.classList.remove('open');
                                d.style.maxHeight = null;
                            }
                        });
                        preferenceTechniquesDiv.querySelectorAll('.flow-description.open').forEach(d => {
                             d.classList.remove('open');
                             d.style.maxHeight = null;
                        });


                        if (isOpen) {
                            description.classList.remove('open');
                            description.style.maxHeight = null;
                            if (step.dataset.step === 'pref') preferenceTechniquesDiv.classList.add('hidden');
                        } else {
                            description.classList.add('open');
                            description.style.maxHeight = description.scrollHeight + "px";
                            if (step.dataset.step === 'pref') preferenceTechniquesDiv.classList.remove('hidden');
                            else preferenceTechniquesDiv.classList.add('hidden');
                        }
                    });
                });
                 preferenceTechniquesDiv.querySelectorAll('.flow-step').forEach(step => {
                    const description = step.querySelector('.flow-description');
                    step.addEventListener('click', () => {
                        const isOpen = description.classList.contains('open');
                         preferenceTechniquesDiv.querySelectorAll('.flow-description.open').forEach(d => {
                            if (d !== description) {
                                d.classList.remove('open');
                                d.style.maxHeight = null;
                            }
                        });
                        if (isOpen) {
                            description.classList.remove('open');
                            description.style.maxHeight = null;
                        } else {
                            description.classList.add('open');
                            description.style.maxHeight = description.scrollHeight + "px";
                        }
                    });
                });
            }

            // Sampling Strategies Cards Interaction
            const samplingCards = document.querySelectorAll('.sampling-card');
            samplingCards.forEach(card => {
                const detailsDiv = card.querySelector('.sampling-details');
                detailsDiv.textContent = card.dataset.details; // Populate details from data attribute
                card.addEventListener('click', () => {
                    const isOpen = detailsDiv.classList.contains('hidden');
                    // Optional: Close other open cards
                    // samplingCards.forEach(otherCard => {
                    //     if (otherCard !== card) {
                    //         otherCard.querySelector('.sampling-details').classList.add('hidden');
                    //     }
                    // });
                    if (isOpen) {
                        detailsDiv.classList.remove('hidden');
                    } else {
                        detailsDiv.classList.add('hidden');
                    }
                });
            });

            // Chart.js Radar Chart for Challenges
            const radarCtx = document.getElementById('challengesRadarChart');
            if (radarCtx) {
                new Chart(radarCtx, {
                    type: 'radar',
                    data: {
                        labels: ['Inconsistencies', 'Hallucinations', 'Bias', 'Interpretability', 'Evaluation'],
                        datasets: [{
                            label: 'Perceived Difficulty/Impact',
                            data: [7, 9, 8, 7, 9], // Conceptual values
                            fill: true,
                            backgroundColor: 'rgba(20, 184, 166, 0.2)', // teal-500 with opacity
                            borderColor: 'rgb(20, 184, 166)', // teal-500
                            pointBackgroundColor: 'rgb(20, 184, 166)',
                            pointBorderColor: '#fff',
                            pointHoverBackgroundColor: '#fff',
                            pointHoverBorderColor: 'rgb(20, 184, 166)'
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        elements: {
                            line: {
                                borderWidth: 2
                            }
                        },
                        scales: {
                            r: {
                                angleLines: { display: true },
                                suggestedMin: 0,
                                suggestedMax: 10,
                                pointLabels: { font: { size: 10 } },
                                ticks: { backdropPadding: 0, stepSize: 2}
                            }
                        },
                        plugins: {
                            legend: {
                                position: 'top',
                                labels: { font: {size: 12}}
                            }
                        }
                    }
                });
            }

            if (navLinks.length > 0) showSection(navLinks[0].dataset.target);
        });
    </script>
</body>
</html>
